{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-15T20:16:33.791436239Z",
     "start_time": "2023-12-15T20:16:25.142016196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jary/.local/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 890 entries, 0 to 889\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   PassengerId      890 non-null    int64              \n",
      " 1   event_timestamp  890 non-null    datetime64[ns, UTC]\n",
      " 2   Survived         890 non-null    int64              \n",
      " 3   Pclass           890 non-null    int64              \n",
      " 4   Name             890 non-null    object             \n",
      " 5   Sex              890 non-null    object             \n",
      " 6   Age              713 non-null    float64            \n",
      " 7   SibSp            890 non-null    int64              \n",
      " 8   Parch            890 non-null    int64              \n",
      " 9   Ticket           890 non-null    object             \n",
      " 10  Fare             890 non-null    float64            \n",
      " 11  Cabin            204 non-null    object             \n",
      " 12  Embarked         888 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n",
      "None\n",
      "------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417 entries, 0 to 416\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   PassengerId      417 non-null    int64              \n",
      " 1   event_timestamp  417 non-null    datetime64[ns, UTC]\n",
      " 2   Pclass           417 non-null    int64              \n",
      " 3   Name             417 non-null    object             \n",
      " 4   Sex              417 non-null    object             \n",
      " 5   Age              332 non-null    float64            \n",
      " 6   SibSp            417 non-null    int64              \n",
      " 7   Parch            417 non-null    int64              \n",
      " 8   Ticket           417 non-null    object             \n",
      " 9   Fare             416 non-null    float64            \n",
      " 10  Cabin            91 non-null     object             \n",
      " 11  Embarked         417 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(4), object(5)\n",
      "memory usage: 39.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from feast import FeatureStore\n",
    "from feast.infra.offline_stores.file_source import SavedDatasetFileStorage\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "# normally, this is where we'd zoom in on a timeframe or subset of interest, but this is a small dataset for training, grab it all\n",
    "entity_df = pd.DataFrame.from_dict({ \"PassengerId\": list(range(1, 891)) })\n",
    "entity_df[\"event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n",
    "train_df = store.get_historical_features(\n",
    "    entity_df=entity_df, features=store.get_feature_service('omniscient_service')\n",
    ").to_df()\n",
    "\n",
    "# and grab the test input data as well\n",
    "entity_df = pd.DataFrame.from_dict({ \"PassengerId\": list(range(892, 1309)) })\n",
    "entity_df[\"event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n",
    "test_df = store.get_historical_features(\n",
    "    entity_df=entity_df, features=store.get_feature_service('test_service')\n",
    ").to_df()\n",
    "\n",
    "print(train_df.info())\n",
    "print('-'*30)\n",
    "print (test_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df # dup. records: 0\n"
     ]
    }
   ],
   "source": [
    "#   we already checked for duplicate records, but could do so again from omniscient_service\n",
    "print('train_df # dup. records:', train_df.duplicated().sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T20:16:33.793611481Z",
     "start_time": "2023-12-15T20:16:33.791912253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols in train_df w/nulls: \n",
      "PassengerId          0\n",
      "event_timestamp      0\n",
      "Survived             0\n",
      "Pclass               0\n",
      "Name                 0\n",
      "Sex                  0\n",
      "Age                177\n",
      "SibSp                0\n",
      "Parch                0\n",
      "Ticket               0\n",
      "Fare                 0\n",
      "Cabin              686\n",
      "Embarked             2\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "cols in test_df w/nulls: \n",
      "PassengerId          0\n",
      "event_timestamp      0\n",
      "Pclass               0\n",
      "Name                 0\n",
      "Sex                  0\n",
      "Age                 85\n",
      "SibSp                0\n",
      "Parch                0\n",
      "Ticket               0\n",
      "Fare                 1\n",
      "Cabin              326\n",
      "Embarked             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "print (\"cols in train_df w/nulls: \")\n",
    "print(train_df.isnull().sum())\n",
    "print('-'*40)\n",
    "print(\"cols in test_df w/nulls: \")\n",
    "print(test_df.isnull().sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T20:16:33.825415484Z",
     "start_time": "2023-12-15T20:16:33.794588784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# possible / needed sanitization tasks:\n",
    "# TODO: complete & abstract for Age\n",
    "# TODO: complete for Embarked & normalize\n",
    "# TODO: normalize Sex\n",
    "# TODO: complete & abstract for Fare\n",
    "# TODO: title abstraction\n",
    "# TODO: complete & abstract for Cabin (to Deck)\n",
    "# TODO: abstract family count / alone from Parch & SibSp\n",
    "\n",
    "# combine datasets for when we want to sanitize both at once\n",
    "combined = [train_df, test_df]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T20:16:33.841149573Z",
     "start_time": "2023-12-15T20:16:33.811496308Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
